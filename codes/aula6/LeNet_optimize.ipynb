{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet_optimize.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filiperobotic/cursoDL/blob/master/codes/aula5/LeNet_optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WppfDvBhkFfd",
        "colab_type": "code",
        "outputId": "68548144-916f-4a6f-db94-8a63da644fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "#from pyimagesearch.nn.conv import LeNet\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "U27CsX1OkewH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f72b01c5-305f-4715-96e8-3f5cd3083965"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import regularizers\n",
        "\n",
        "def build_LeNet(width, height, depth, classes):\n",
        "  # initialize the model\n",
        "  model = Sequential()\n",
        "  inputShape = (height, width, depth)\n",
        "\n",
        "  # first set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(20, (5, 5), padding=\"same\",\n",
        "  input_shape=inputShape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "  # second set of CONV => RELU => POOL layers\n",
        "  model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "  # first (and only) set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(500))\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # return the constructed network architecture\n",
        "  return model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PU54qS0nD7QS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "def build_MiniVGG(width, height, depth, classes):\n",
        "  # initialize the model\n",
        "  model = Sequential()\n",
        "  inputShape = (height, width, depth)# first CONV => RELU => CONV => RELU => POOL layer set\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "  input_shape=inputShape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # second CONV => RELU => CONV => RELU => POOL layer set\n",
        "  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(axis=2))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # first (and only) set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  # return the constructed network architecture\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wu3wYs1lK6P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a minute)\n",
        "print(\"[INFO] accessing MNIST...\")\n",
        "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heWhVwACkSti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainData = trainData.reshape((trainData.shape[0], 28, 28, 1))\n",
        "testData = testData.reshape((testData.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkR7Uur6lhXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "trainData = trainData.astype(\"float32\") / 255.0\n",
        "testData = testData.astype(\"float32\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "le = LabelBinarizer()\n",
        "trainLabels = le.fit_transform(trainLabels)\n",
        "testLabels = le.transform(testLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XZ3nqAwlqMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=0.01)\n",
        "model = build_LeNet(width=28, height=28, depth=1, classes=10)\n",
        "#model = build_MiniVGG(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainData, trainLabels,\n",
        "     validation_data=(testData, testLabels), batch_size=128,\n",
        "     epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aARU6R8oltXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testData, batch_size=128)\n",
        "print(classification_report(testLabels.argmax(axis=1),\n",
        "predictions.argmax(axis=1),\n",
        "target_names=[str(x) for x in le.classes_]))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"acc\" ], label=\"train_acc\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKFbHMMzCHIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhkt2ScNGwya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## cifar"
      ]
    },
    {
      "metadata": {
        "id": "qEl80AGNGx47",
        "colab_type": "code",
        "outputId": "d827a208-ead4-4ddc-e7df-c0d5c23412ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# load the training and testing data, then scale it into the\n",
        "# range [0, 1]\n",
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float32\")/255.0\n",
        "testX = testX.astype(\"float32\")/255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "# initialize the label names for the CIFAR-10 dataset\n",
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\",\"frog\", \"horse\", \"ship\", \"truck\" ]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3uV7HDxkHQhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = SGD(lr=0.01)\n",
        "model = build_LeNet(width=32, height=32, depth=3, classes=10)\n",
        "#model = build_MiniVGG(width=32, height=32, depth=3, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainX, trainY,\n",
        "     validation_data=(testX, testY), batch_size=128,\n",
        "     epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkumElTUH622",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "predictions.argmax(axis=1),\n",
        "target_names=labelNames))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"acc\" ], label=\"train_acc\" )\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKLZ1tAKLDrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}