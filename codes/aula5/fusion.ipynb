{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fusion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filiperobotic/cursoDL/blob/master/codes/aula7/fusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WnO6Dqjd6S1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/filiperobotic/aula7.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EP1b-s296fkr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers import Input\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QI6P1NV7Pft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_single(width, height, depth, classes):\n",
        "\n",
        "    inputShape = (height, width, depth)\n",
        "    \n",
        "    input1 = Input(shape=inputShape)\n",
        "    x = Conv2D(64, (11,11), input_shape=inputShape,\n",
        "\t\t\tpadding=\"same\")(input1)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    \n",
        "    x = Conv2D(128, (5, 5), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    \n",
        "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Dense(classes)(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "    \n",
        "    model = Model(inputs=input1, outputs=x)\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AedVsJ44V4gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_double(width, height, depth, classes):\n",
        "\t\t\n",
        "    #TODO\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gG-48oLp7WMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        " \n",
        "# import the necessary packages\n",
        "#from pyimagesearch.simplenet import SimpleNet\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "from imutils import build_montages\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "arg_dataset1 = \"aula7/lung/planox\"\n",
        "arg_dataset2 = \"aula7/lung/planoy\"\n",
        "arg_epochs = 30\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths1 = list(paths.list_images(arg_dataset1))\n",
        "imagePaths2 = list(paths.list_images(arg_dataset2))\n",
        "data1 = []\n",
        "labels1 = []\n",
        "\n",
        "# loop over the image paths 1\n",
        "for imagePath in imagePaths1:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, convert it to grayscale, and resize it to be a\n",
        "\t# fixed 64x64 pixels, ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\timage = cv2.resize(image, (64, 64))\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata1.append(image)\n",
        "\tlabels1.append(label)\n",
        "  \n",
        "data2 = []\n",
        "#labels2 = labels1\n",
        "  \n",
        "# loop over the image paths 2\n",
        "for imagePath in imagePaths2:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, convert it to grayscale, and resize it to be a\n",
        "\t# fixed 64x64 pixels, ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\timage = cv2.resize(image, (64, 64))\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata2.append(image)\n",
        "\n",
        "# convert the data into a NumPy array, then preprocess it by scaling\n",
        "# all pixel intensities to the range [0, 1]\n",
        "data1 = np.array(data1, dtype=\"float\") / 255.0\n",
        "data2 = np.array(data2, dtype=\"float\") / 255.0\n",
        "\n",
        "# reshape the data matrix so that it explicity includes a channel\n",
        "# dimension\n",
        "data1 = data1.reshape((data1.shape[0], data1.shape[1], data1.shape[2], 1))\n",
        "data2 = data2.reshape((data2.shape[0], data2.shape[1], data2.shape[2], 1))\n",
        "\n",
        "# encode the labels (which are currently strings) as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels1)\n",
        "\n",
        "# transform the labels into vectors in the range [0, classes],\n",
        "# generating a vector for each label, where the index of the label\n",
        "# is set to '1' and all other entries are set to '0' -- this process\n",
        "# is called \"one-hot encoding\"\n",
        "labels = np_utils.to_categorical(labels, 2)\n",
        "\n",
        "(trainX_d1, testX_d1, trainY_d1, testY_d1) = train_test_split(data1, labels,\n",
        " \ttest_size=0.40, stratify=labels, random_state=42)\n",
        "\n",
        "(trainX_d2, testX_d2, trainY_d2, testY_d2) = train_test_split(data2, labels,\n",
        " \ttest_size=0.40, stratify=labels, random_state=42)\n",
        "\n",
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "\n",
        "opt = Adam(lr=1e-5, decay=1e-5 / arg_epochs)\n",
        "model = build_single(width=64, height=64, depth=1,\n",
        "\tclasses=2)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network for {} epochs...\".format(\n",
        "\targ_epochs))\n",
        "H = model.fit(trainX_d1, trainY, validation_data=(testX_d1, testY_d1),\n",
        "\tbatch_size=32, epochs=arg_epochs, verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XylX1NnFUG7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX_d1, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=le.classes_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fn3ovd1wO9yR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}